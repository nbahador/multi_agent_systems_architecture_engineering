mcp-servers/cloudbuild.yaml 
# =============================================================================
# GOOGLE CLOUD BUILD TEMPLATE FOR MULTI-CONTAINER DEPLOYMENT
# =============================================================================
# 
# PURPOSE: This template builds, pushes, and deploys multiple Docker containers
# to Google Cloud Run in parallel for better performance.
#
# WHAT YOU NEED BEFORE USING:
# 1. A Google Cloud Project with Cloud Build API enabled
# 2. Docker repositories created in Google Artifact Registry
# 3. Separate folders for each service containing Dockerfiles
# 4. Cloud Build trigger or manual execution setup
#
# HOW TO CUSTOMIZE: 
# 1. Replace all PLACEHOLDER values with your actual values
# 2. Modify the number of services (add/remove build-push-deploy blocks)
# 3. Update service names, folder paths, and deployment configurations
# 4. Set your environment variables in the substitutions section
#
# =============================================================================

steps:
# =============================================================================
# BUILD PHASE: Create Docker Images for Each Service
# =============================================================================
# This section builds Docker containers from your source code
# Add one build step for each service you want to deploy

# --- BUILD SERVICE 1 ---
- name: 'gcr.io/cloud-builders/docker'
  id: 'build-SERVICE_1_NAME'                    # PLACEHOLDER: Replace with descriptive name (e.g., 'build-user-api')
  args: 
    - 'build'                                   # Docker build command
    - '-t'                                      # Tag flag for naming the image
    - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/SERVICE_1_IMAGE_NAME:${_IMAGE_TAG}'  
    # PLACEHOLDER: Replace SERVICE_1_IMAGE_NAME with your image name (e.g., 'user-api')
    - './SERVICE_1_FOLDER_PATH'                 # PLACEHOLDER: Replace with folder containing Dockerfile (e.g., './backend/api')

# --- BUILD SERVICE 2 ---
- name: 'gcr.io/cloud-builders/docker'
  id: 'build-SERVICE_2_NAME'                    # PLACEHOLDER: Replace with descriptive name (e.g., 'build-frontend')
  args:
    - 'build'
    - '-t'
    - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/SERVICE_2_IMAGE_NAME:${_IMAGE_TAG}'
    # PLACEHOLDER: Replace SERVICE_2_IMAGE_NAME with your image name (e.g., 'frontend-app')
    - './SERVICE_2_FOLDER_PATH'                 # PLACEHOLDER: Replace with folder path (e.g., './frontend')

# --- ADD MORE BUILD STEPS HERE ---
# Copy the pattern above for additional services
# Remember to:
# - Use unique 'id' values
# - Update SERVICE_X_NAME, SERVICE_X_IMAGE_NAME, and SERVICE_X_FOLDER_PATH
# - Ensure each folder contains a valid Dockerfile

# =============================================================================
# PUSH PHASE: Upload Images to Container Registry
# =============================================================================
# This section pushes your built images to Google Artifact Registry
# Add one push step for each service (matches build steps above)

# --- PUSH SERVICE 1 ---
- name: 'gcr.io/cloud-builders/docker'
  id: 'push-SERVICE_1_NAME'                     # PLACEHOLDER: Match the SERVICE_1_NAME from build step
  waitFor: ['build-SERVICE_1_NAME']             # PLACEHOLDER: Wait for corresponding build step to complete
  args:
    - 'push'                                    # Docker push command
    - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/SERVICE_1_IMAGE_NAME:${_IMAGE_TAG}'
    # PLACEHOLDER: Must exactly match the image name from build step

# --- PUSH SERVICE 2 ---
- name: 'gcr.io/cloud-builders/docker'
  id: 'push-SERVICE_2_NAME'                     # PLACEHOLDER: Match the SERVICE_2_NAME from build step
  waitFor: ['build-SERVICE_2_NAME']             # PLACEHOLDER: Wait for corresponding build step to complete
  args:
    - 'push'
    - '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/SERVICE_2_IMAGE_NAME:${_IMAGE_TAG}'

# --- ADD MORE PUSH STEPS HERE ---
# Follow the same pattern for additional services

# =============================================================================
# DEPLOY PHASE: Deploy to Google Cloud Run
# =============================================================================
# This section deploys your pushed images to Cloud Run services
# Add one deploy step for each service

# --- DEPLOY SERVICE 1 ---
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
  id: 'deploy-SERVICE_1_NAME'                   # PLACEHOLDER: Match SERVICE_1_NAME from previous steps
  waitFor: ['push-SERVICE_1_NAME']              # PLACEHOLDER: Wait for corresponding push step
  entrypoint: gcloud                            # Use gcloud CLI tool
  args:
    - 'run'                                     # Cloud Run command
    - 'deploy'                                  # Deploy subcommand
    - 'SERVICE_1_CLOUD_RUN_NAME'                # PLACEHOLDER: Name of your Cloud Run service (e.g., 'user-api-service')
    - '--image=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/SERVICE_1_IMAGE_NAME:${_IMAGE_TAG}'
    - '--region=${_REGION}'                     # Deploy to specified region
    - '--platform=managed'                     # Use fully managed Cloud Run
    - '--labels=PROJECT_LABEL_KEY=PROJECT_LABEL_VALUE'  # PLACEHOLDER: Replace with your project labels (e.g., 'app=myproject')
    - '--allow-unauthenticated'                 # CUSTOMIZE: Remove this line if you want authentication required
    - '--set-env-vars=ENV_VAR_1=${_ENV_VAR_1},ENV_VAR_2=${_ENV_VAR_2}'  # PLACEHOLDER: Add your environment variables
    - '--min-instances=MIN_INSTANCE_COUNT'      # PLACEHOLDER: Set minimum instances (e.g., '0' for cost savings, '1' for no cold starts)
    - '--max-instances=MAX_INSTANCE_COUNT'      # PLACEHOLDER: Set maximum instances (e.g., '10')
    - '--memory=MEMORY_ALLOCATION'              # PLACEHOLDER: Set memory (e.g., '512Mi', '1Gi', '2Gi')
    - '--cpu=CPU_ALLOCATION'                    # PLACEHOLDER: Set CPU (e.g., '1', '2', '4')

# --- DEPLOY SERVICE 2 ---
- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
  id: 'deploy-SERVICE_2_NAME'                   # PLACEHOLDER: Match SERVICE_2_NAME from previous steps
  waitFor: ['push-SERVICE_2_NAME']              # PLACEHOLDER: Wait for corresponding push step
  entrypoint: gcloud
  args:
    - 'run'
    - 'deploy'
    - 'SERVICE_2_CLOUD_RUN_NAME'                # PLACEHOLDER: Name of your Cloud Run service (e.g., 'frontend-service')
    - '--image=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/SERVICE_2_IMAGE_NAME:${_IMAGE_TAG}'
    - '--region=${_REGION}'
    - '--platform=managed'
    - '--labels=PROJECT_LABEL_KEY=PROJECT_LABEL_VALUE'
    - '--allow-unauthenticated'                 # CUSTOMIZE: Remove if authentication needed
    - '--set-env-vars=ENV_VAR_3=${_ENV_VAR_3}'  # PLACEHOLDER: Add environment variables specific to this service
    - '--min-instances=MIN_INSTANCE_COUNT'      # PLACEHOLDER: Set minimum instances
    - '--max-instances=MAX_INSTANCE_COUNT'      # PLACEHOLDER: Set maximum instances
    - '--memory=MEMORY_ALLOCATION'              # PLACEHOLDER: Set memory allocation
    - '--cpu=CPU_ALLOCATION'                    # PLACEHOLDER: Set CPU allocation

# --- ADD MORE DEPLOY STEPS HERE ---
# Follow the same pattern for additional services

# =============================================================================
# CONFIGURATION VARIABLES
# =============================================================================
# These variables are used throughout the build process
# Customize these values for your specific project

substitutions:
  # --- INFRASTRUCTURE SETTINGS ---
  _REGION: "YOUR_REGION"                        # PLACEHOLDER: Your preferred region (e.g., "us-central1", "europe-west1")
  _REPO_NAME: "YOUR_REPOSITORY_NAME"            # PLACEHOLDER: Your Artifact Registry repository name (e.g., "my-app-repo")
  _IMAGE_TAG: "latest"                          # CUSTOMIZE: Image tag (e.g., "latest", "v1.0", "$COMMIT_SHA")
  
  # --- ENVIRONMENT VARIABLES ---
  # Add all environment variables your services need
  _ENV_VAR_1: "VALUE_1"                         # PLACEHOLDER: Replace with actual env var name and value (e.g., "_DATABASE_URL: 'postgres://...'")
  _ENV_VAR_2: "VALUE_2"                         # PLACEHOLDER: Add more as needed (e.g., "_API_KEY: '${_SECRET_API_KEY}'")
  _ENV_VAR_3: "VALUE_3"                         # PLACEHOLDER: Service-specific variables
  
  # --- ADDITIONAL CUSTOM VARIABLES ---
  # Add any other variables your deployment needs
  # _CUSTOM_VAR: "CUSTOM_VALUE"                 # PLACEHOLDER: Add custom variables as needed

# =============================================================================
# OPTIONAL CONFIGURATIONS
# =============================================================================

# --- Build Options (uncomment and customize if needed) ---
# options:
#   machineType: 'E2_HIGHCPU_8'                # CUSTOMIZE: Build machine type for faster builds
#   substitutionOption: 'ALLOW_LOOSE'          # Allow undefined substitution variables
#   logging: 'CLOUD_LOGGING_ONLY'              # Log to Cloud Logging only

# --- Timeout (uncomment if builds take longer than 10 minutes) ---
# timeout: '1200s'                             # CUSTOMIZE: Set build timeout (default: 600s)

# =============================================================================
# TEMPLATE USAGE GUIDE
# =============================================================================
#
# STEP 1: PROJECT SETUP
# - Replace all PLACEHOLDER values with your actual project details
# - Ensure your Google Cloud Project has necessary APIs enabled:
#   * Cloud Build API
#   * Cloud Run API  
#   * Artifact Registry API
#
# STEP 2: FOLDER STRUCTURE
# Your project should look like this:
# project-root/
# ├── cloudbuild.yaml (this file)
# ├── SERVICE_1_FOLDER_PATH/
# │   ├── Dockerfile
# │   └── (your service 1 code)
# ├── SERVICE_2_FOLDER_PATH/
# │   ├── Dockerfile
# │   └── (your service 2 code)
# └── (other folders as needed)
#
# STEP 3: ARTIFACT REGISTRY SETUP
# Create your repository: 
# gcloud artifacts repositories create YOUR_REPOSITORY_NAME \
#   --repository-format=docker \
#   --location=YOUR_REGION
#
# STEP 4: EXECUTE BUILD
# Option A - Manual trigger:
# gcloud builds submit --config cloudbuild.yaml
#
# Option B - Set up automatic triggers in Cloud Build console
#
# =============================================================================

# =============================================================================
# SIMPLE EXAMPLE: E-COMMERCE APPLICATION
# =============================================================================
# Here's how this template would look when filled out for a real project:
#
# steps:
# # Build Phase
# - name: 'gcr.io/cloud-builders/docker'
#   id: 'build-user-api'
#   args: ['build', '-t', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/user-api:latest', './backend/users']
#
# - name: 'gcr.io/cloud-builders/docker'
#   id: 'build-product-api'
#   args: ['build', '-t', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/product-api:latest', './backend/products']
#
# - name: 'gcr.io/cloud-builders/docker'
#   id: 'build-frontend'
#   args: ['build', '-t', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/web-frontend:latest', './frontend']
#
# # Push Phase
# - name: 'gcr.io/cloud-builders/docker'
#   id: 'push-user-api'
#   waitFor: ['build-user-api']
#   args: ['push', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/user-api:latest']
#
# - name: 'gcr.io/cloud-builders/docker'
#   id: 'push-product-api'
#   waitFor: ['build-product-api']
#   args: ['push', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/product-api:latest']
#
# - name: 'gcr.io/cloud-builders/docker'
#   id: 'push-frontend'
#   waitFor: ['build-frontend']
#   args: ['push', '${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/web-frontend:latest']
#
# # Deploy Phase
# - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
#   id: 'deploy-user-api'
#   waitFor: ['push-user-api']
#   entrypoint: gcloud
#   args:
#     - 'run'
#     - 'deploy'
#     - 'ecommerce-user-api'
#     - '--image=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/user-api:latest'
#     - '--region=${_REGION}'
#     - '--platform=managed'
#     - '--labels=app=ecommerce,service=users'
#     - '--allow-unauthenticated'
#     - '--set-env-vars=DATABASE_URL=${_DATABASE_URL},JWT_SECRET=${_JWT_SECRET}'
#     - '--min-instances=1'
#     - '--max-instances=5'
#     - '--memory=1Gi'
#     - '--cpu=1'
#
# - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
#   id: 'deploy-product-api'
#   waitFor: ['push-product-api']
#   entrypoint: gcloud
#   args:
#     - 'run'
#     - 'deploy'
#     - 'ecommerce-product-api'
#     - '--image=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/product-api:latest'
#     - '--region=${_REGION}'
#     - '--platform=managed'
#     - '--labels=app=ecommerce,service=products'
#     - '--allow-unauthenticated'
#     - '--set-env-vars=DATABASE_URL=${_DATABASE_URL},REDIS_URL=${_REDIS_URL}'
#     - '--min-instances=0'
#     - '--max-instances=10'
#     - '--memory=512Mi'
#     - '--cpu=1'
#
# - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
#   id: 'deploy-frontend'
#   waitFor: ['push-frontend']
#   entrypoint: gcloud
#   args:
#     - 'run'
#     - 'deploy'
#     - 'ecommerce-frontend'
#     - '--image=${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/web-frontend:latest'
#     - '--region=${_REGION}'
#     - '--platform=managed'
#     - '--labels=app=ecommerce,service=frontend'
#     - '--allow-unauthenticated'
#     - '--set-env-vars=API_BASE_URL=${_API_BASE_URL}'
#     - '--min-instances=1'
#     - '--max-instances=3'
#     - '--memory=512Mi'
#     - '--cpu=1'
#
# substitutions:
#   _REGION: "us-central1"
#   _REPO_NAME: "ecommerce-containers"
#   _IMAGE_TAG: "latest"
#   _DATABASE_URL: "postgresql://user:pass@db.example.com/ecommerce"
#   _JWT_SECRET: "your-super-secret-jwt-key-here"
#   _REDIS_URL: "redis://redis.example.com:6379"
#   _API_BASE_URL: "https://ecommerce-product-api-xyz.a.run.app"
#
# =============================================================================








mcp-servers/general/main.py
# =====================================
# FUNCTION-BASED MCP SERVER TEMPLATE
# =====================================
# This template helps you create an MCP server that exposes Python functions
# as tools that AI assistants can use. Perfect for calculations, data processing,
# and business logic that doesn't require external APIs.

import asyncio
import json
import uvicorn
import os
from dotenv import load_dotenv
from mcp import types as mcp_types 
from mcp.server.lowlevel import Server
from mcp.server.sse import SseServerTransport
from starlette.applications import Starlette
from starlette.routing import Mount, Route
from google.adk.tools.function_tool import FunctionTool
from google.adk.tools.mcp_tool.conversion_utils import adk_to_mcp_tool_type

# =====================================
# ENVIRONMENT CONFIGURATION
# =====================================
# Load environment variables from .env file
load_dotenv()

# CUSTOMIZE: Set your server host and port
APP_HOST = os.environ.get("APP_HOST", "0.0.0.0")  # Server host (usually keep as 0.0.0.0)
APP_PORT = os.environ.get("APP_PORT", 8080)       # Server port (change if needed)

# ADD MORE: Include any additional environment variables you need
# API_KEY = os.environ.get("API_KEY")               # Example: API keys
# DATABASE_URL = os.environ.get("DATABASE_URL")     # Example: Database connections
# SECRET_KEY = os.environ.get("SECRET_KEY")         # Example: Security keys

# =====================================
# FUNCTION DEFINITIONS SECTION
# =====================================
# REPLACE ALL FUNCTIONS BELOW: Create your own business logic functions
# Each function should:
# 1. Have clear parameters with type hints
# 2. Include a detailed docstring
# 3. Return a string result
# 4. Handle errors gracefully

def your_calculation_function(input_value: int) -> str:
    """
    REPLACE: Write your function description here.
    
    This function should describe exactly what it does and when to use it.
    The AI assistant will read this to understand when to call this function.
    
    Args:
        input_value: REPLACE - Describe what this parameter is for
        
    Returns:
        str: REPLACE - Describe what the function returns
        
    Example: "Calculates compound interest on an investment amount"
    """
    try:
        # REPLACE: Add your calculation or business logic here
        # Examples of what you can do:
        # - Mathematical calculations: result = input_value ** 2
        # - Data transformations: processed_data = transform(input_value)
        # - File operations: content = read_file(input_value)
        # - String processing: formatted = format_text(input_value)
        
        # Example calculation:
        result = input_value * 2  # Replace with your logic
        
        # CUSTOMIZE: Return a meaningful success message
        return f"Calculation completed successfully! Result: {result}"
        
    except Exception as e:
        # CUSTOMIZE: Return a meaningful error message
        return f"Calculation failed. Error: {str(e)}"


def your_processing_function(text_input: str, multiplier: int) -> str:
    """
    REPLACE: Another function example with multiple parameters.
    
    This function demonstrates how to handle multiple input parameters
    and perform more complex processing operations.
    
    Args:
        text_input: REPLACE - Describe the text parameter
        multiplier: REPLACE - Describe the numeric parameter
        
    Returns:
        str: REPLACE - Describe the return value
        
    Example: "Processes text data and applies formatting rules"
    """
    try:
        # REPLACE: Add your processing logic here
        # Examples:
        # - Text processing: result = text_input.upper()
        # - Data validation: if validate(text_input): ...
        # - Complex calculations: score = calculate_score(text_input, multiplier)
        # - Data formatting: formatted = format_output(text_input, multiplier)
        
        # Example processing:
        processed_text = text_input * multiplier  # Replace with your logic
        
        # CUSTOMIZE: Return your processed result
        return f"Text processing completed! Processed: {processed_text}"
        
    except Exception as e:
        # CUSTOMIZE: Handle errors appropriately
        return f"Text processing failed. Error: {str(e)}"


def your_data_function(data_list: list) -> str:
    """
    REPLACE: Function that works with lists or complex data.
    
    This function shows how to handle more complex data types
    like lists, dictionaries, or custom objects.
    
    Args:
        data_list: REPLACE - Describe the list parameter
        
    Returns:
        str: REPLACE - Describe what analysis is returned
        
    Example: "Analyzes a list of sales data and returns summary statistics"
    """
    try:
        # REPLACE: Add your data processing logic here
        # Examples:
        # - List analysis: average = sum(data_list) / len(data_list)
        # - Data filtering: filtered = [x for x in data_list if x > threshold]
        # - Statistical analysis: stats = calculate_statistics(data_list)
        # - Data aggregation: summary = aggregate_data(data_list)
        
        # Example analysis:
        if not data_list:
            return "No data provided for analysis."
        
        total = sum(data_list)
        average = total / len(data_list)
        maximum = max(data_list)
        minimum = min(data_list)
        
        # CUSTOMIZE: Return your analysis results
        return f"Data analysis complete! Total: {total}, Average: {average:.2f}, Max: {maximum}, Min: {minimum}"
        
    except Exception as e:
        # CUSTOMIZE: Handle data processing errors
        return f"Data analysis failed. Error: {str(e)}"

# ADD MORE FUNCTIONS: Copy the patterns above to create additional functions
# def your_fourth_function(param1: str) -> str:
#     """Your fourth function description."""
#     try:
#         # Your implementation here
#         result = process_data(param1)
#         return f"Success: {result}"
#     except Exception as e:
#         return f"Error: {str(e)}"

# =====================================
# TOOL REGISTRATION SECTION
# =====================================
# REPLACE: Create FunctionTool instances for each of your functions
# The variable name should be descriptive and end with "Tool"

your_calculation_functionTool = FunctionTool(your_calculation_function)
your_processing_functionTool = FunctionTool(your_processing_function)
your_data_functionTool = FunctionTool(your_data_function)

# ADD MORE TOOLS: Create tool instances for additional functions
# your_fourth_functionTool = FunctionTool(your_fourth_function)

# REGISTER ALL TOOLS: Add your tools to this dictionary
# Key = tool name, Value = tool instance
available_tools = {
    your_calculation_functionTool.name: your_calculation_functionTool,
    your_processing_functionTool.name: your_processing_functionTool,
    your_data_functionTool.name: your_data_functionTool,
    # ADD MORE: your_fourth_functionTool.name: your_fourth_functionTool,
}

# =====================================
# MCP SERVER SETUP SECTION
# =====================================
# CUSTOMIZE: Change the server name to describe your server's purpose
app = Server("Your-Function-Server")  # Replace with a descriptive name
sse = SseServerTransport("/messages/")

@app.list_tools()
async def list_tools() -> list[mcp_types.Tool]:
    """
    MCP handler to list available tools.
    DO NOT MODIFY: This function tells AI assistants what tools are available.
    """
    # Convert all tools to MCP format
    mcp_tools = []
    for tool_name, tool_instance in available_tools.items():
        schema = adk_to_mcp_tool_type(tool_instance)
        mcp_tools.append(schema)
        print(f"MCP Server: Advertising tool: {schema.name}")
    
    print(f"MCP Server: Received list_tools request. Total tools: {len(mcp_tools)}")
    return mcp_tools

@app.call_tool()
async def call_tool(
    name: str, arguments: dict
) -> list[mcp_types.TextContent | mcp_types.ImageContent | mcp_types.EmbeddedResource]:
    """
    MCP handler to execute a tool call.
    DO NOT MODIFY: This function executes tools when called by AI assistants.
    """
    print(f"MCP Server: Received call_tool request for '{name}' with args: {arguments}")

    # Look up the tool by name in our registry
    tool_to_call = available_tools.get(name)
    if tool_to_call:
        try:
            # Execute the function tool
            adk_response = await tool_to_call.run_async(
                args=arguments,
                tool_context=None,  # No ADK context needed for function tools
            )
            print(f"MCP Server: Tool '{name}' executed successfully.")
            
            # Return the response as MCP text content
            response_text = json.dumps(adk_response, indent=2)
            return [mcp_types.TextContent(type="text", text=response_text)]

        except Exception as e:
            print(f"MCP Server: Error executing tool '{name}': {e}")
            # Return error as JSON
            error_text = json.dumps({"error": f"Failed to execute tool '{name}': {str(e)}"})
            return [mcp_types.TextContent(type="text", text=error_text)]
    else:
        # Handle calls to unknown tools
        print(f"MCP Server: Tool '{name}' not found.")
        error_text = json.dumps({"error": f"Tool '{name}' not implemented."})
        return [mcp_types.TextContent(type="text", text=error_text)]

# =====================================
# SERVER TRANSPORT SECTION
# =====================================
# DO NOT MODIFY: This section handles the MCP communication protocol

async def handle_sse(request):
    """Handles Server-Sent Events for MCP communication."""
    async with sse.connect_sse(
        request.scope, request.receive, request._send
    ) as streams:
        await app.run(
            streams[0], streams[1], app.create_initialization_options()
        )

# Create the Starlette ASGI application
starlette_app = Starlette(
    debug=True,  # CUSTOMIZE: Set to False in production
    routes=[
        Route("/sse", endpoint=handle_sse),
        Mount("/messages/", app=sse.handle_post_message),
    ],
)

# =====================================
# SERVER STARTUP SECTION
# =====================================
# CUSTOMIZE: You can modify the startup messages but keep the core logic

if __name__ == "__main__":
    # CUSTOMIZE: Update these startup messages to match your server
    print("🚀 Launching Your Function-Based MCP Server...")
    print(f"📡 Server will run on {APP_HOST}:{APP_PORT}")
    print(f"🔧 Available tools: {list(available_tools.keys())}")
    print(f"📋 Total functions exposed: {len(available_tools)}")
    
    try:
        # Start the server
        asyncio.run(uvicorn.run(starlette_app, host=APP_HOST, port=APP_PORT))
    except KeyboardInterrupt:
        print("\n⏹️  MCP Server stopped by user.")
    except Exception as e:
        print(f"❌ MCP Server encountered an error: {e}")
    finally:
        print("🔚 MCP Server process exiting.")

# =====================================
# FUNCTION TYPES REFERENCE GUIDE
# =====================================
"""
PARAMETER TYPES YOU CAN USE:
===========================
- int: Whole numbers (1, 42, -5)
- float: Decimal numbers (3.14, -2.5, 0.0)
- str: Text strings ("hello", "file.txt")
- bool: True/False values
- list: Lists of items ([1, 2, 3], ["a", "b", "c"])
- dict: Key-value pairs ({"name": "John", "age": 30})

RETURN TYPE:
============
Always return str: Your functions should always return a string message
that describes the result or any errors that occurred.
"""

# =====================================
# COMPLETE EXAMPLES: BUSINESS FUNCTIONS
# =====================================
"""
EXAMPLE 1: FINANCIAL CALCULATOR SERVER
=====================================

def calculate_compound_interest(principal: float, rate: float, time: int, compounds_per_year: int) -> str:
    '''Calculates compound interest for investments.'''
    try:
        amount = principal * (1 + rate/compounds_per_year) ** (compounds_per_year * time)
        interest = amount - principal
        return f"Investment Result: Principal ${principal:,.2f}, Final Amount ${amount:,.2f}, Interest Earned ${interest:,.2f}"
    except Exception as e:
        return f"Calculation error: {str(e)}"

def calculate_loan_payment(loan_amount: float, annual_rate: float, years: int) -> str:
    '''Calculates monthly payment for a loan.'''
    try:
        monthly_rate = annual_rate / 12
        num_payments = years * 12
        if monthly_rate == 0:
            payment = loan_amount / num_payments
        else:
            payment = loan_amount * (monthly_rate * (1 + monthly_rate)**num_payments) / ((1 + monthly_rate)**num_payments - 1)
        total_paid = payment * num_payments
        total_interest = total_paid - loan_amount
        return f"Loan Payment: ${payment:.2f}/month, Total Paid: ${total_paid:,.2f}, Total Interest: ${total_interest:,.2f}"
    except Exception as e:
        return f"Loan calculation error: {str(e)}"

def calculate_retirement_savings(monthly_contribution: float, annual_return: float, years: int) -> str:
    '''Calculates retirement savings projection.'''
    try:
        monthly_return = annual_return / 12
        months = years * 12
        if monthly_return == 0:
            total = monthly_contribution * months
        else:
            total = monthly_contribution * (((1 + monthly_return)**months - 1) / monthly_return)
        contributed = monthly_contribution * months
        gains = total - contributed
        return f"Retirement Projection: Total Savings ${total:,.2f}, Contributions ${contributed:,.2f}, Investment Gains ${gains:,.2f}"
    except Exception as e:
        return f"Retirement calculation error: {str(e)}"

# Tool Registration:
calculate_compound_interestTool = FunctionTool(calculate_compound_interest)
calculate_loan_paymentTool = FunctionTool(calculate_loan_payment)
calculate_retirement_savingsTool = FunctionTool(calculate_retirement_savings)

available_tools = {
    calculate_compound_interestTool.name: calculate_compound_interestTool,
    calculate_loan_paymentTool.name: calculate_loan_paymentTool,
    calculate_retirement_savingsTool.name: calculate_retirement_savingsTool,
}

# Server Name:
app = Server("Financial-Calculator-Server")

EXAMPLE 2: TEXT PROCESSING SERVER
================================

def analyze_text_sentiment(text: str) -> str:
    '''Analyzes the sentiment of provided text.'''
    try:
        # Simple sentiment analysis (replace with actual NLP library)
        positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic']
        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'disappointing', 'poor']
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        if positive_count > negative_count:
            sentiment = "Positive"
        elif negative_count > positive_count:
            sentiment = "Negative"
        else:
            sentiment = "Neutral"
            
        return f"Sentiment Analysis: {sentiment} (Positive words: {positive_count}, Negative words: {negative_count})"
    except Exception as e:
        return f"Sentiment analysis error: {str(e)}"

def count_words_and_chars(text: str) -> str:
    '''Counts words, characters, and provides text statistics.'''
    try:
        word_count = len(text.split())
        char_count = len(text)
        char_count_no_spaces = len(text.replace(' ', ''))
        sentence_count = text.count('.') + text.count('!') + text.count('?')
        
        return f"Text Statistics: {word_count} words, {char_count} characters, {char_count_no_spaces} chars (no spaces), {sentence_count} sentences"
    except Exception as e:
        return f"Text analysis error: {str(e)}"

def format_text_case(text: str, case_type: str) -> str:
    '''Formats text in different cases (upper, lower, title, sentence).'''
    try:
        case_type = case_type.lower()
        
        if case_type == "upper":
            result = text.upper()
        elif case_type == "lower":
            result = text.lower()
        elif case_type == "title":
            result = text.title()
        elif case_type == "sentence":
            result = text.capitalize()
        else:
            return f"Invalid case type. Use: upper, lower, title, or sentence"
            
        return f"Text formatted as {case_type}: {result}"
    except Exception as e:
        return f"Text formatting error: {str(e)}"

EXAMPLE 3: DATA VALIDATION SERVER
===============================

def validate_email(email: str) -> str:
    '''Validates if an email address is properly formatted.'''
    try:
        import re
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        
        if re.match(pattern, email):
            return f"✅ Email '{email}' is valid"
        else:
            return f"❌ Email '{email}' is not valid"
    except Exception as e:
        return f"Email validation error: {str(e)}"

def validate_phone_number(phone: str, country_code: str) -> str:
    '''Validates phone number format for different countries.'''
    try:
        import re
        
        # Remove all non-digit characters
        digits_only = re.sub(r'[^\d]', '', phone)
        
        patterns = {
            'US': r'^\d{10}$',           # 10 digits for US
            'UK': r'^\d{11}$',           # 11 digits for UK
            'CA': r'^\d{10}$',           # 10 digits for Canada
        }
        
        pattern = patterns.get(country_code.upper())
        if not pattern:
            return f"❌ Unsupported country code: {country_code}"
            
        if re.match(pattern, digits_only):
            return f"✅ Phone number '{phone}' is valid for {country_code}"
        else:
            return f"❌ Phone number '{phone}' is not valid for {country_code}"
    except Exception as e:
        return f"Phone validation error: {str(e)}"

def validate_credit_card(card_number: str) -> str:
    '''Validates credit card number using Luhn algorithm.'''
    try:
        import re
        
        # Remove spaces and dashes
        card_number = re.sub(r'[^\d]', '', card_number)
        
        # Basic length check
        if len(card_number) < 13 or len(card_number) > 19:
            return f"❌ Credit card number must be 13-19 digits"
        
        # Luhn algorithm
        def luhn_check(card_num):
            digits = [int(d) for d in card_num]
            for i in range(len(digits) - 2, -1, -2):
                digits[i] *= 2
                if digits[i] > 9:
                    digits[i] -= 9
            return sum(digits) % 10 == 0
        
        if luhn_check(card_number):
            return f"✅ Credit card number is valid (Luhn check passed)"
        else:
            return f"❌ Credit card number is invalid (Luhn check failed)"
    except Exception as e:
        return f"Credit card validation error: {str(e)}"
"""

# =====================================
# CUSTOMIZATION CHECKLIST
# =====================================
"""
STEP-BY-STEP CUSTOMIZATION GUIDE:
=================================

1. ENVIRONMENT SETUP:
   □ Create .env file with APP_HOST and APP_PORT
   □ Add any additional environment variables you need
   □ Install required dependencies: pip install uvicorn python-dotenv

2. FUNCTION REPLACEMENT:
   □ Replace all example functions with your own business logic
   □ Update function names to be descriptive
   □ Write clear docstrings explaining what each function does
   □ Add proper parameter type hints
   □ Include error handling in each function

3. TOOL REGISTRATION:
   □ Create FunctionTool instances for each function
   □ Update tool variable names to match your functions
   □ Add all tools to the available_tools dictionary
   □ Remove any unused tool registrations

4. SERVER CONFIGURATION:
   □ Change the server name in Server() constructor
   □ Update startup messages to reflect your server's purpose
   □ Modify APP_PORT if you need a different port

5. TESTING:
   □ Test each function individually
   □ Verify the server starts without errors
   □ Test tool listing endpoint
   □ Test tool execution with sample parameters

COMMON FUNCTION PATTERNS:
========================

CALCULATION FUNCTIONS:
- Mathematical operations (interest, taxes, conversions)
- Statistical analysis (averages, trends, forecasts)
- Engineering calculations (physics, chemistry formulas)

PROCESSING FUNCTIONS: 
- Text manipulation (formatting, parsing, cleaning)
- Data transformation (JSON processing, CSV handling)
- Image processing (resize, format conversion)

VALIDATION FUNCTIONS:
- Input validation (emails, phone numbers, IDs)
- Data integrity checks (checksums, format verification)
- Business rule validation (price ranges, date limits)

UTILITY FUNCTIONS:
- Date/time operations (formatting, calculations, timezones)
- File operations (reading, writing, processing)
- String operations (encoding, hashing, templating)

ENVIRONMENT VARIABLES TO SET:
============================
Create a .env file with:

# Server Configuration
APP_HOST=0.0.0.0
APP_PORT=8080

# Add your own variables as needed:
# API_KEY=your_api_key_here
# DATABASE_URL=your_database_url
# SECRET_KEY=your_secret_key
# MAX_PROCESSING_SIZE=1000000
"""

# =====================================
# DEPENDENCIES INSTALLATION
# =====================================
"""
REQUIRED DEPENDENCIES:
=====================
pip install uvicorn python-dotenv starlette

OPTIONAL DEPENDENCIES (add based on your functions):
===================================================
pip install requests          # For HTTP API calls
pip install pandas           # For data processing
pip install numpy            # For numerical calculations
pip install pillow           # For image processing
pip install beautifulsoup4   # For HTML/XML parsing
pip install openpyxl         # For Excel file processing
pip install python-dateutil # For advanced date handling
pip install cryptography     # For encryption/hashing
pip install sqlalchemy      # For database operations
pip install pydantic        # For data validation
"""

# =====================================
# USAGE EXAMPLES
# =====================================
"""
HOW TO USE YOUR MCP SERVER:
==========================

1. Start your server:
   python main.py

2. Connect from an agent (in another script):
   from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset
   from google.adk.tools.mcp_tool.mcp_session_manager import SseServerParams
   
   tools = MCPToolset(
       connection_params=SseServerParams(url="http://localhost:8080", headers={})
   )

3. Use in an LlmAgent:
   agent = LlmAgent(
       model='gemini-2.5-flash',
       name='my_agent',
       instruction="You can perform calculations and data processing.",
       tools=tools
   )

TESTING YOUR FUNCTIONS:
======================
Test your functions directly before deploying:

# Test calculation function
result = your_calculation_function(42)
print(result)

# Test processing function  
result = your_processing_function("hello world", 3)
print(result)

# Test data function
result = your_data_function([1, 2, 3, 4, 5])
print(result)
"""




mcp-servers/diagnose/agent.py
# =====================================
# MCP AGENT TEMPLATE - Complete Guide
# =====================================
# This template helps you create a multi-agent system that can:
# 1. Connect to multiple MCP tool servers
# 2. Use database tools via toolbox
# 3. Coordinate between specialized agents
# 4. Handle complex workflows with delegation

import asyncio
import os
from contextlib import AsyncExitStack
from dotenv import load_dotenv
from google.adk.agents.llm_agent import LlmAgent
from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset
from google.adk.tools.mcp_tool.mcp_session_manager import SseServerParams
import logging 
import nest_asyncio 
from toolbox_core import ToolboxSyncClient

# =====================================
# ENVIRONMENT SETUP SECTION
# =====================================
# Load environment variables - ALWAYS keep this at the top
load_dotenv()

# Configure logging - CUSTOMIZE: Change log level if needed (DEBUG, INFO, WARNING, ERROR)
logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

# =====================================
# GLOBAL VARIABLES SECTION
# =====================================
# DO NOT MODIFY: These are needed for proper agent lifecycle management
root_agent: LlmAgent | None = None
exit_stack: AsyncExitStack | None = None

# =====================================
# URL CONFIGURATION SECTION
# =====================================
# REPLACE THESE: Set your MCP server URLs in environment variables
# These should point to your running MCP servers

# CUSTOMIZE: Database tools URL (from your db-toolbox server)
DB_TOOLS_URL = os.environ.get("DB_TOOLS_URL")
# Example: "http://localhost:8080" or "https://your-db-server.com"

# CUSTOMIZE: API tools URL (from your function-based MCP server)
API_TOOLS_URL = os.environ.get("API_TOOLS_URL") 
# Example: "http://localhost:8081" or "https://your-api-server.com"

# CUSTOMIZE: Function tools URL (from another MCP server if you have one)
FUNCTION_TOOLS_URL = os.environ.get("FUNCTION_TOOLS_URL")
# Example: "http://localhost:8082" or "https://your-function-server.com"

# ADD MORE URLS: If you have additional MCP servers
# EXTRA_TOOLS_URL = os.environ.get("EXTRA_TOOLS_URL")

# Debug print statements - CUSTOMIZE: Update these to match your URLs
print(f"DB_TOOLS_URL: {DB_TOOLS_URL}")
print(f"API_TOOLS_URL: {API_TOOLS_URL}")
print(f"FUNCTION_TOOLS_URL: {FUNCTION_TOOLS_URL}")

# =====================================
# AGENT CREATION FUNCTION
# =====================================
async def get_agent_async():
    """
    Creates and configures your multi-agent system.
    
    CUSTOMIZE THIS FUNCTION: Modify to create your own agents and tool connections.
    
    Returns:
        LlmAgent: The main coordinating agent
    """
    
    # Print URLs for debugging
    print(f"Connecting to DB_TOOLS_URL: {DB_TOOLS_URL}")
    print(f"Connecting to API_TOOLS_URL: {API_TOOLS_URL}")
    print(f"Connecting to FUNCTION_TOOLS_URL: {FUNCTION_TOOLS_URL}")

    # =====================================
    # TOOLSET CONNECTIONS SECTION
    # =====================================
    # CUSTOMIZE: Connect to your database toolbox
    toolbox = ToolboxSyncClient(DB_TOOLS_URL)
    
    # REPLACE: Load your specific toolset from the database server
    # This should match a toolset name from your tools.yaml file
    toolDB = toolbox.load_toolset('YOUR-TOOLSET-NAME')  # Replace with your actual toolset name
    
    # CUSTOMIZE: Connect to your API-based MCP servers
    toolAPI = MCPToolset(
        connection_params=SseServerParams(url=API_TOOLS_URL, headers={})
    )
    
    toolFunction = MCPToolset(
        connection_params=SseServerParams(url=FUNCTION_TOOLS_URL, headers={})
    )
    
    # ADD MORE TOOLSETS: Connect to additional MCP servers if needed
    # toolExtra = MCPToolset(
    #     connection_params=SseServerParams(url=EXTRA_TOOLS_URL, headers={})
    # )

    # =====================================
    # SPECIALIZED AGENTS SECTION
    # =====================================
    # REPLACE THESE: Create your own specialized agents
    
    # AGENT 1: Database/Information Retrieval Agent
    # CUSTOMIZE: This agent handles data lookup and retrieval
    db_agent = LlmAgent(
        model='gemini-2.5-flash',  # CUSTOMIZE: Choose your preferred model
        name='YOUR_DB_AGENT_NAME',  # REPLACE: Give your agent a meaningful name
        instruction="""
            REPLACE THIS INSTRUCTION: Define what this agent does.
            
            Example instructions:
            - "You are a Data Analyst. Your job is to query databases and retrieve information."
            - "You are a Customer Service Agent. Look up customer data and order history."
            - "You are a Research Assistant. Search databases for relevant information."
            
            Be specific about:
            - What this agent should do
            - What tools it should use
            - What it should NOT do
        """,
        tools=toolDB  # This agent uses database tools
    )
    
    # AGENT 2: Action/API Agent  
    # CUSTOMIZE: This agent handles actions and external API calls
    api_agent = LlmAgent(
        model='gemini-2.5-flash',  # CUSTOMIZE: Choose your preferred model
        name='YOUR_API_AGENT_NAME',  # REPLACE: Give your agent a meaningful name
        instruction="""
            REPLACE THIS INSTRUCTION: Define what this agent does.
            
            Example instructions:
            - "You are an Integration Agent. Execute API calls and external actions."
            - "You are a Notification Agent. Send emails, SMS, and push notifications."
            - "You are an Automation Agent. Trigger workflows and process data."
            
            Be specific about:
            - What actions this agent can perform
            - Which APIs it should call
            - Any limitations or safety guidelines
        """,
        tools=[toolFunction, toolAPI]  # This agent uses function and API tools
    )
    
    # ADD MORE AGENTS: Create additional specialized agents if needed
    # analytics_agent = LlmAgent(
    #     model='gemini-2.5-flash',
    #     name='analytics_agent',
    #     instruction="You analyze data and generate reports.",
    #     tools=toolExtra
    # )

    # =====================================
    # MASTER COORDINATOR AGENT
    # =====================================
    # CUSTOMIZE: This is your main agent that delegates to specialists
    root_agent = LlmAgent(
        model='gemini-2.5-flash',  # CUSTOMIZE: Choose your preferred model
        name='YOUR_MASTER_AGENT_NAME',  # REPLACE: Name your coordinator agent
        instruction="""
            REPLACE THIS INSTRUCTION: Define how your master agent delegates tasks.
            
            You are the Master Coordinator. Your job is to analyze user requests 
            and delegate them to the right specialist agent.
            
            CUSTOMIZE: List your agents and their roles:
            - **YOUR_DB_AGENT_NAME**: Handles all data lookup, search, and retrieval tasks
            - **YOUR_API_AGENT_NAME**: Handles all actions, API calls, and external operations
            
            DELEGATION RULES:
            - For questions about existing data → delegate to YOUR_DB_AGENT_NAME
            - For actions that change things → delegate to YOUR_API_AGENT_NAME
            - For analysis tasks → delegate to [specify which agent]
            
            You do NOT perform tasks yourself - you only coordinate and delegate.
        """,
        sub_agents=[db_agent, api_agent],  # LIST: Include all your specialized agents
        # sub_agents=[db_agent, api_agent, analytics_agent],  # ADD MORE: Include additional agents
    )
    
    print("✅ Multi-agent system created successfully.")
    return root_agent

# =====================================
# INITIALIZATION FUNCTION
# =====================================
# DO NOT MODIFY: This function handles proper agent initialization
async def initialize():
    """Initializes the global root_agent safely."""
    global root_agent
    if root_agent is None:
        log.info("🔄 Initializing agent system...")
        root_agent = await get_agent_async()
        if root_agent:
            log.info("✅ Agent system initialized successfully.")
        else:
            log.error("❌ Agent system initialization failed.")
    else:
        log.info("ℹ️  Agent system already initialized.")

# =====================================
# MODULE STARTUP SECTION
# =====================================
# DO NOT MODIFY: This handles the async initialization properly
nest_asyncio.apply()

log.info("🚀 Starting agent initialization...")
try:
    asyncio.run(initialize())
    log.info("✅ Module initialization completed successfully.")
except RuntimeError as e:
    log.error(f"⚠️  RuntimeError during initialization (likely nested loops): {e}", exc_info=True)
except Exception as e:
    log.error(f"❌ Unexpected error during initialization: {e}", exc_info=True)

# =====================================
# OPTIONAL: ADDITIONAL FUNCTIONS
# =====================================
# ADD YOUR OWN: Create helper functions for your specific use case

def get_agent():
    """
    OPTIONAL: Synchronous wrapper to get the initialized agent.
    CUSTOMIZE: Add your own helper functions here.
    """
    global root_agent
    if root_agent is None:
        raise RuntimeError("Agent not initialized. Call initialize() first.")
    return root_agent

# ADD MORE HELPERS: Create additional utility functions as needed
# def reset_agent():
#     """Resets the agent system."""
#     global root_agent
#     root_agent = None

# def is_agent_ready():
#     """Checks if the agent system is ready."""
#     return root_agent is not None

# =====================================
# ENVIRONMENT VARIABLES GUIDE
# =====================================
"""
CREATE A .env FILE with these variables:

# Database Tools Server
DB_TOOLS_URL=http://localhost:8080

# API Tools Server  
API_TOOLS_URL=http://localhost:8081

# Function Tools Server
FUNCTION_TOOLS_URL=http://localhost:8082

# Add any additional MCP server URLs:
# EXTRA_TOOLS_URL=http://localhost:8083

# Add any API keys or secrets:
# OPENAI_API_KEY=your_openai_key
# DATABASE_PASSWORD=your_db_password
"""

# =====================================
# COMPLETE EXAMPLE: CUSTOMER SERVICE SYSTEM
# =====================================
"""
EXAMPLE CONFIGURATION: Customer Service Multi-Agent System
---------------------------------------------------------

Environment Variables (.env file):
DB_TOOLS_URL=http://localhost:8080
API_TOOLS_URL=http://localhost:8081  
NOTIFICATION_TOOLS_URL=http://localhost:8082

Agent Configuration:

# Database Agent - Handles customer data lookup
customer_data_agent = LlmAgent(
    model='gemini-2.5-flash',
    name='customer_data_agent',
    instruction='''
        You are a Customer Data Specialist. Your role is to:
        - Look up customer information and order history
        - Search product catalogs and inventory
        - Retrieve account details and preferences
        - Find transaction records and billing information
        
        Use your database tools to answer questions about existing data.
        You do NOT create, update, or delete anything.
    ''',
    tools=customer_db_tools
)

# Action Agent - Handles operations and notifications
customer_action_agent = LlmAgent(
    model='gemini-2.5-flash',
    name='customer_action_agent', 
    instruction='''
        You are a Customer Action Specialist. Your role is to:
        - Send notifications (email, SMS, push)
        - Process refunds and cancellations
        - Update customer preferences
        - Create support tickets
        - Trigger automated workflows
        
        Use your API tools to perform actions and make changes.
        Always confirm actions before executing them.
    ''',
    tools=[notification_tools, api_tools]
)

# Master Coordinator
customer_service_coordinator = LlmAgent(
    model='gemini-2.5-flash',
    name='customer_service_coordinator',
    instruction='''
        You are the Customer Service Coordinator. Analyze requests and delegate:
        
        DELEGATE TO customer_data_agent:
        - "What's my order status?"
        - "Show me my purchase history"
        - "Do you have this product in stock?"
        - "What's my account balance?"
        
        DELEGATE TO customer_action_agent:
        - "Cancel my order"
        - "Send me a receipt"
        - "Update my email address"
        - "Process my refund"
        
        You coordinate but don't perform the actual work.
    ''',
    sub_agents=[customer_data_agent, customer_action_agent]
)

EXAMPLE 2: Content Management System
----------------------------------

# Content Retrieval Agent
content_retrieval_agent = LlmAgent(
    model='gemini-2.5-flash',
    name='content_retrieval_agent',
    instruction='''
        You are a Content Librarian. You:
        - Search articles, blogs, and documents
        - Retrieve user-generated content
        - Find media files and metadata
        - Look up content analytics and stats
        
        Use database tools to find existing content.
    ''',
    tools=content_db_tools
)

# Content Management Agent  
content_management_agent = LlmAgent(
    model='gemini-2.5-flash',
    name='content_management_agent',
    instruction='''
        You are a Content Manager. You:
        - Publish new articles and posts
        - Update existing content
        - Moderate and approve submissions
        - Send content notifications
        - Manage content workflows
        
        Use API tools to create and modify content.
    ''',
    tools=[publishing_tools, moderation_tools]
)

# Content Coordinator
content_coordinator = LlmAgent(
    model='gemini-2.5-flash',
    name='content_coordinator',
    instruction='''
        You coordinate content operations:
        
        For SEARCHING/FINDING content → delegate to content_retrieval_agent
        For CREATING/UPDATING content → delegate to content_management_agent
    ''',
    sub_agents=[content_retrieval_agent, content_management_agent]
)

EXAMPLE 3: E-commerce Analytics System
------------------------------------

# Data Analysis Agent
analytics_agent = LlmAgent(
    model='gemini-2.5-flash',
    name='analytics_agent',
    instruction='''
        You are a Business Intelligence Analyst. You:
        - Generate sales reports and metrics
        - Analyze customer behavior patterns
        - Track inventory trends
        - Calculate KPIs and performance metrics
        
        Use database tools to query and analyze data.
    ''',
    tools=analytics_db_tools
)

# Automation Agent
automation_agent = LlmAgent(
    model='gemini-2.5-flash', 
    name='automation_agent',
    instruction='''
        You are an Operations Automation Specialist. You:
        - Trigger marketing campaigns
        - Send automated reports
        - Update inventory levels
        - Process bulk operations
        
        Use API tools to execute automated tasks.
    ''',
    tools=[marketing_tools, inventory_tools]
)

# Business Coordinator
business_coordinator = LlmAgent(
    model='gemini-2.5-flash',
    name='business_coordinator', 
    instruction='''
        You coordinate business operations:
        
        For REPORTS/ANALYSIS → delegate to analytics_agent
        For AUTOMATION/ACTIONS → delegate to automation_agent
    ''',
    sub_agents=[analytics_agent, automation_agent]
)
"""

# =====================================
# AGENT CREATION FUNCTION
# =====================================
async def get_agent_async():
    """
    Creates and configures your multi-agent system.
    
    MAIN CUSTOMIZATION AREA: This is where you define your agents and their roles.
    
    Returns:
        LlmAgent: The main coordinating agent
    """
    
    # Debug print statements
    print(f"🔗 Connecting to DB_TOOLS_URL: {DB_TOOLS_URL}")
    print(f"🔗 Connecting to API_TOOLS_URL: {API_TOOLS_URL}")
    print(f"🔗 Connecting to FUNCTION_TOOLS_URL: {FUNCTION_TOOLS_URL}")

    # =====================================
    # TOOLSET CONNECTIONS
    # =====================================
    # STEP 1: Connect to your database toolbox server
    toolbox = ToolboxSyncClient(DB_TOOLS_URL)
    
    # REPLACE: Load your specific toolset (must match name in tools.yaml)
    toolDB = toolbox.load_toolset('YOUR-TOOLSET-NAME')  
    # Example: toolDB = toolbox.load_toolset('customer-management')
    
    # STEP 2: Connect to your MCP function servers
    # CUSTOMIZE: Add connection parameters and headers if needed
    toolAPI = MCPToolset(
        connection_params=SseServerParams(url=API_TOOLS_URL, headers={})
    )
    
    toolFunction = MCPToolset(
        connection_params=SseServerParams(url=FUNCTION_TOOLS_URL, headers={})
    )
    
    # ADD MORE: Connect to additional MCP servers
    # toolExtra = MCPToolset(
    #     connection_params=SseServerParams(url=EXTRA_TOOLS_URL, headers={})
    # )

    # =====================================
    # SPECIALIZED AGENTS CREATION
    # =====================================
    # AGENT 1: Database/Retrieval Specialist
    # CUSTOMIZE: This agent handles all data retrieval operations
    db_agent = LlmAgent(
        model='gemini-2.5-flash',  # CUSTOMIZE: Change model if needed (gpt-4, claude-3, etc.)
        name='YOUR_DB_AGENT_NAME',  # REPLACE: Choose a descriptive name
        instruction="""
            REPLACE THIS ENTIRE INSTRUCTION with your agent's role.
            
            TEMPLATE:
            You are a [ROLE NAME]. Your job is to:
            - [What this agent does - be specific]
            - [What tools it uses]
            - [What it should NOT do]
            
            EXAMPLES:
            - Data lookup and search operations
            - Customer information retrieval  
            - Product catalog queries
            - Historical data analysis
            
            Use your database tools to find and retrieve information.
            You do NOT create, update, or delete data.
        """,
        tools=toolDB  # Uses database tools only
    )
    
    # AGENT 2: Action/API Specialist
    # CUSTOMIZE: This agent handles all action-based operations
    api_agent = LlmAgent(
        model='gemini-2.5-flash',  # CUSTOMIZE: Change model if needed
        name='YOUR_API_AGENT_NAME',  # REPLACE: Choose a descriptive name
        instruction="""
            REPLACE THIS ENTIRE INSTRUCTION with your agent's role.
            
            TEMPLATE:
            You are a [ROLE NAME]. Your job is to:
            - [What actions this agent performs]
            - [What APIs it calls]
            - [What changes it can make]
            
            EXAMPLES:
            - Send notifications and communications
            - Process payments and transactions
            - Update records and preferences
            - Trigger automated workflows
            
            Use your API and function tools to perform actions and make changes.
            Always confirm important actions before executing.
        """,
        tools=[toolFunction, toolAPI]  # Uses function and API tools
    )
    
    # ADD MORE AGENTS: Create additional specialists if needed
    # analysis_agent = LlmAgent(
    #     model='gemini-2.5-flash',
    #     name='analysis_agent',
    #     instruction="You perform data analysis and generate insights.",
    #     tools=toolExtra
    # )

    # =====================================
    # MASTER COORDINATOR AGENT
    # =====================================
    # CUSTOMIZE: This is your main orchestrating agent
    root_agent = LlmAgent(
        model='gemini-2.5-flash',  # CUSTOMIZE: Change model if needed
        name='YOUR_MASTER_COORDINATOR_NAME',  # REPLACE: Name your main agent
        instruction="""
            REPLACE THIS ENTIRE INSTRUCTION with your coordination logic.
            
            TEMPLATE:
            You are the [SYSTEM NAME] Coordinator. Your role is to analyze user requests 
            and delegate them to the correct specialist agent.
            
            You command these specialists:
            - **YOUR_DB_AGENT_NAME**: Delegate requests for [describe when to use]
            - **YOUR_API_AGENT_NAME**: Delegate requests for [describe when to use]
            
            DELEGATION EXAMPLES:
            - Questions starting with "What", "Show me", "Find" → YOUR_DB_AGENT_NAME
            - Actions starting with "Send", "Create", "Update", "Process" → YOUR_API_AGENT_NAME
            
            IMPORTANT: You analyze and delegate only. You do NOT perform tasks yourself.
        """,
        sub_agents=[db_agent, api_agent],  # LIST: All your specialized agents
        # sub_agents=[db_agent, api_agent, analysis_agent],  # ADD MORE: Include additional agents
    )
    
    print("✅ Multi-agent system created successfully.")
    return root_agent

# =====================================
# INITIALIZATION HANDLER
# =====================================
# DO NOT MODIFY: This section handles proper async initialization
async def initialize():
    """Initializes the global root_agent safely."""
    global root_agent
    if root_agent is None:
        log.info("🔄 Initializing agent system...")
        root_agent = await get_agent_async()
        if root_agent:
            log.info("✅ Agent system initialized successfully.")
        else:
            log.error("❌ Agent system initialization failed.")
    else:
        log.info("ℹ️  Agent system already initialized.")

# =====================================
# MODULE STARTUP EXECUTION
# =====================================
# DO NOT MODIFY: This starts the initialization process
nest_asyncio.apply()

log.info("🚀 Starting agent system initialization...")
try:
    asyncio.run(initialize())
    log.info("✅ Module initialization completed successfully.")
except RuntimeError as e:
    log.error(f"⚠️  RuntimeError during initialization: {e}", exc_info=True)
except Exception as e:
    log.error(f"❌ Unexpected error during initialization: {e}", exc_info=True)

# =====================================
# OPTIONAL: UTILITY FUNCTIONS
# =====================================
# ADD YOUR OWN: Create helper functions for your application

def get_agent():
    """
    Synchronous wrapper to get the initialized agent.
    CUSTOMIZE: Add error handling specific to your use case.
    """
    global root_agent
    if root_agent is None:
        raise RuntimeError("❌ Agent system not initialized. Call initialize() first.")
    return root_agent

def is_system_ready():
    """
    Checks if the agent system is fully initialized and ready.
    CUSTOMIZE: Add additional readiness checks if needed.
    """
    return root_agent is not None

# ADD MORE UTILITIES: Create functions specific to your application
# def restart_system():
#     """Restarts the entire agent system."""
#     global root_agent
#     root_agent = None
#     asyncio.run(initialize())

# def get_system_status():
#     """Returns detailed status of the agent system."""
#     return {
#         "initialized": root_agent is not None,
#         "agents_count": len(root_agent.sub_agents) if root_agent else 0,
#         "db_connected": DB_TOOLS_URL is not None,
#         "api_connected": API_TOOLS_URL is not None
#     }

# =====================================
# TEMPLATE CUSTOMIZATION CHECKLIST
# =====================================
"""
STEP-BY-STEP CUSTOMIZATION GUIDE:
=================================

1. ENVIRONMENT SETUP:
   □ Create .env file with your MCP server URLs
   □ Add any API keys or database credentials
   □ Set up your MCP servers (db-toolbox, function servers)

2. TOOLSET CONFIGURATION:
   □ Replace 'YOUR-TOOLSET-NAME' with your actual toolset from tools.yaml
   □ Update DB_TOOLS_URL, API_TOOLS_URL, FUNCTION_TOOLS_URL
   □ Add additional toolset connections if needed

3. AGENT CUSTOMIZATION:
   □ Replace 'YOUR_DB_AGENT_NAME' with a meaningful name
   □ Replace 'YOUR_API_AGENT_NAME' with a meaningful name  
   □ Replace 'YOUR_MASTER_COORDINATOR_NAME' with a meaningful name
   □ Update all agent instructions with your specific roles
   □ Add additional specialized agents if needed

4. DELEGATION LOGIC:
   □ Define clear rules for when to use each agent
   □ Update the master coordinator's delegation instructions
   □ Test that requests are routed to the correct agents

5. TESTING:
   □ Verify all MCP servers are running
   □ Test database connections
   □ Verify agent initialization
   □ Test end-to-end workflows

COMMON USE CASES:
================
- Customer Service (data lookup + actions)
- Content Management (search + publishing)
- E-commerce Operations (catalog + orders)
- Business Intelligence (analysis + reporting)
- IT Operations (monitoring + automation)
- Financial Services (data + transactions)
"""




mcp-servers/db-toolbox/tools.yaml
# =====================================
# DATABASE TOOLBOX YAML TEMPLATE
# =====================================
# This YAML file configures database connections and SQL tools for MCP servers
# Replace all PLACEHOLDER values with your actual configuration

# =====================================
# SOURCES SECTION - Database Connections
# =====================================
# Define your database connections here. You can have multiple databases.
sources:
  # REPLACE: Change "your-database-name" to a meaningful name for your database
  your-database-name:
    # CHOOSE ONE: Select your database type (uncomment the one you need)
    
    # For PostgreSQL (Google Cloud SQL or regular PostgreSQL):
    kind: cloud-sql-postgres  # Use "postgres" for regular PostgreSQL
    
    # For MySQL (uncomment if using MySQL):
    # kind: cloud-sql-mysql    # Use "mysql" for regular MySQL
    
    # For SQLite (uncomment if using SQLite):
    # kind: sqlite
    # path: "/path/to/your/database.db"  # Only needed for SQLite
    
    # GOOGLE CLOUD SQL SPECIFIC (remove if not using Google Cloud):
    project: "YOUR-GOOGLE-CLOUD-PROJECT-ID"      # Replace with your GCP project ID
    region: "YOUR-REGION"                        # Replace with your region (e.g., "us-central1", "europe-west1")
    instance: "YOUR-INSTANCE-NAME"               # Replace with your Cloud SQL instance name
    
    # DATABASE CONNECTION DETAILS:
    database: "YOUR-DATABASE-NAME"               # Replace with your actual database name
    user: "YOUR-USERNAME"                        # Replace with your database username
    password: "YOUR-PASSWORD"                    # Replace with your database password
    
    # FOR REGULAR POSTGRES/MYSQL (uncomment if not using Google Cloud):
    # host: "localhost"                          # Database host (e.g., "localhost", "db.example.com")
    # port: 5432                                 # Database port (5432 for PostgreSQL, 3306 for MySQL)

  # ADD MORE DATABASES: Copy the pattern above for additional database connections
  # secondary-database:
  #   kind: postgres
  #   host: "secondary-db.example.com"
  #   database: "analytics_db"
  #   user: "analytics_user"
  #   password: "secure_password"

# =====================================
# TOOLS SECTION - Database Operations
# =====================================
# Define SQL queries that will be exposed as tools to AI assistants
tools:
  
  # REPLACE: Create your first tool
  your-first-tool:
    kind: postgres-sql                           # Match the database type from sources
    source: your-database-name                   # Must match a source name defined above
    
    # CUSTOMIZE: Write a clear description of what this tool does
    description: "REPLACE: Describe what this SQL query does and when to use it"
    
    # DEFINE PARAMETERS: List any input parameters for your SQL query
    parameters:
      - name: parameter_name                     # REPLACE: Name of your parameter
        type: string                             # CHOOSE: string, integer, number, boolean
        description: "REPLACE: Explain what this parameter is for"
      
      # ADD MORE PARAMETERS: Copy the pattern above for additional parameters
      # - name: another_parameter
      #   type: integer
      #   description: "Another parameter description"
    
    # WRITE YOUR SQL: Replace with your actual SQL query
    statement: |
      SELECT column1, column2 
      FROM your_table 
      WHERE your_column = $1;
      -- $1, $2, $3... correspond to parameters in order
      -- Use proper SQL syntax for your database type

  # REPLACE: Create your second tool
  your-second-tool:
    kind: postgres-sql
    source: your-database-name
    description: "REPLACE: Another tool description"
    parameters:
      - name: param1
        type: string
        description: "Parameter 1 description"
      - name: param2
        type: integer
        description: "Parameter 2 description"
    statement: |
      UPDATE your_table 
      SET column1 = $1 
      WHERE id = $2;

  # ADD MORE TOOLS: Copy the pattern above for additional SQL tools
  # your-third-tool:
  #   kind: postgres-sql
  #   source: your-database-name
  #   description: "Third tool description"
  #   parameters: []  # No parameters needed
  #   statement: |
  #     SELECT COUNT(*) as total_records FROM your_table;

# =====================================
# TOOLSETS SECTION - Group Related Tools
# =====================================
# Group your tools into logical sets for organization
toolsets:
  # REPLACE: Change "your-toolset-name" to describe your tool group
  your-toolset-name:
    # LIST YOUR TOOLS: Include all tools that belong to this group
    - your-first-tool
    - your-second-tool
    # - your-third-tool
  
  # ADD MORE TOOLSETS: Create additional groups if needed
  # admin-tools:
  #   - create-user-tool
  #   - delete-user-tool
  # reporting-tools:
  #   - generate-report-tool
  #   - export-data-tool

# =====================================
# PARAMETER TYPES REFERENCE
# =====================================
# Use these parameter types in your tool definitions:
# - string: Text values (e.g., names, descriptions)
# - integer: Whole numbers (e.g., IDs, counts)
# - number: Decimal numbers (e.g., prices, measurements)
# - boolean: true/false values
# - array: Lists of values (specify items type)

# =====================================
# SQL PARAMETER REFERENCE
# =====================================
# In your SQL statements, use these placeholders:
# $1 - First parameter
# $2 - Second parameter
# $3 - Third parameter
# And so on...

# =====================================
# COMPLETE EXAMPLE: E-COMMERCE SYSTEM
# =====================================

"""
EXAMPLE CONFIGURATION: E-commerce Database Tools
-----------------------------------------------
This example shows a complete configuration for an e-commerce system:

sources:
  ecommerce-db:
    kind: postgres
    host: "localhost"
    port: 5432
    database: "online_store"
    user: "store_admin"
    password: "secure_password123"

tools:
  search-products:
    kind: postgres-sql
    source: ecommerce-db
    description: "Searches for products by name or category"
    parameters:
      - name: search_term
        type: string
        description: "Product name or category to search for"
    statement: |
      SELECT product_id, product_name, price, stock_quantity, category
      FROM products 
      WHERE product_name ILIKE '%' || $1 || '%' 
         OR category ILIKE '%' || $1 || '%'
      ORDER BY product_name;

  get-customer-orders:
    kind: postgres-sql
    source: ecommerce-db
    description: "Retrieves all orders for a specific customer"
    parameters:
      - name: customer_id
        type: integer
        description: "The unique ID of the customer"
    statement: |
      SELECT o.order_id, o.order_date, o.total_amount, o.status,
             p.product_name, oi.quantity, oi.unit_price
      FROM orders o
      JOIN order_items oi ON o.order_id = oi.order_id
      JOIN products p ON oi.product_id = p.product_id
      WHERE o.customer_id = $1
      ORDER BY o.order_date DESC;

  update-inventory:
    kind: postgres-sql
    source: ecommerce-db
    description: "Updates the stock quantity for a specific product"
    parameters:
      - name: product_id
        type: integer
        description: "The unique ID of the product"
      - name: new_quantity
        type: integer
        description: "The new stock quantity"
    statement: |
      UPDATE products 
      SET stock_quantity = $2, last_updated = CURRENT_TIMESTAMP
      WHERE product_id = $1
      RETURNING product_name, stock_quantity;

  sales-report:
    kind: postgres-sql
    source: ecommerce-db
    description: "Generates a sales report for a specific date range"
    parameters:
      - name: start_date
        type: string
        description: "Start date in YYYY-MM-DD format"
      - name: end_date
        type: string
        description: "End date in YYYY-MM-DD format"
    statement: |
      SELECT 
        p.category,
        COUNT(oi.order_item_id) as items_sold,
        SUM(oi.quantity * oi.unit_price) as total_revenue
      FROM orders o
      JOIN order_items oi ON o.order_id = oi.order_id
      JOIN products p ON oi.product_id = p.product_id
      WHERE o.order_date BETWEEN $1 AND $2
      GROUP BY p.category
      ORDER BY total_revenue DESC;

toolsets:
  product-management:
    - search-products
    - update-inventory
  
  customer-service:
    - get-customer-orders
    - search-products
  
  analytics:
    - sales-report
    - get-customer-orders

"""

# =====================================
# QUICK START CHECKLIST
# =====================================
"""
1. □ Replace 'your-database-name' with your actual database identifier
2. □ Choose and configure your database type (postgres, mysql, sqlite)
3. □ Fill in your database connection details
4. □ Replace example tools with your actual SQL queries
5. □ Update tool descriptions to explain what each query does
6. □ Define parameters for dynamic queries
7. □ Test your SQL statements work correctly
8. □ Group related tools into logical toolsets
9. □ Set up environment variables if using secrets
10. □ Deploy and test your MCP server

COMMON USE CASES:
- Customer data lookup and management
- Inventory tracking and updates
- Sales reporting and analytics
- User authentication and permissions
- Content management and search
- Logging and audit trails
- Data import/export operations
"""




mcp-servers/api/main.py
# MCP Server Template - Complete Guide
# This template helps you create your own MCP (Model Context Protocol) server
# that exposes custom tools/functions to AI assistants like Claude

import asyncio
import json
import uvicorn
import os
from dotenv import load_dotenv
import requests
from mcp import types as mcp_types 
from mcp.server.lowlevel import Server
from mcp.server.sse import SseServerTransport
from starlette.applications import Starlette
from starlette.routing import Mount, Route

# REPLACE THIS: Import your function tool wrapper
from google.adk.tools.function_tool import FunctionTool
from google.adk.tools.mcp_tool.conversion_utils import adk_to_mcp_tool_type

# =====================================
# CONFIGURATION SECTION
# =====================================
# Load environment variables from .env file
load_dotenv()

# CUSTOMIZE THESE: Set your server configuration
APP_HOST = os.environ.get("APP_HOST", "0.0.0.0")  # Server host (usually keep as 0.0.0.0)
APP_PORT = os.environ.get("APP_PORT", 8080)       # Server port (change if needed)

# REPLACE THIS: Add your API endpoint URL if you're calling external services
API_SERVER_URL = os.environ.get('API_SERVER_URL')  # Example: "https://your-api.com"

# =====================================
# FUNCTION DEFINITIONS SECTION
# =====================================
# REPLACE THESE FUNCTIONS: Define your own custom functions here
# Each function should:
# 1. Have a clear docstring describing what it does
# 2. Return a string with the result
# 3. Handle errors gracefully

def your_first_function() -> str:
    """
    REPLACE THIS: Write a description of what your function does.
    This will be shown to the AI assistant so it knows when to use this tool.
    
    Example: "Calculates the square of a number and returns the result."
    """
    try:
        # REPLACE THIS: Add your function logic here
        # Example options:
        # - Call an external API: requests.get("https://api.example.com/data")
        # - Perform calculations: result = number ** 2
        # - Read from database: db.query("SELECT * FROM table")
        # - Process files: with open("file.txt", "r") as f: content = f.read()
        
        # Example implementation:
        response = requests.post(f"{API_SERVER_URL}/your-endpoint")
        response.raise_for_status()
        data = response.json()
        
        # CUSTOMIZE THIS: Return a meaningful success message
        return f"Success! Your function returned: {data.get('result')}"
        
    except requests.exceptions.RequestException as e:
        # CUSTOMIZE THIS: Return a meaningful error message
        return f"Error: Your function failed. Reason: {e}"
    except Exception as e:
        # Handle any other errors
        return f"Unexpected error: {str(e)}"


def your_second_function(parameter1: str, parameter2: int) -> str:
    """
    REPLACE THIS: Another function example with parameters.
    
    Args:
        parameter1: Description of first parameter
        parameter2: Description of second parameter
    
    Example: "Sends a notification message to a specific user ID."
    """
    try:
        # REPLACE THIS: Add your function logic here
        # Example with parameters:
        # result = f"Processing {parameter1} with value {parameter2}"
        
        # Example API call with parameters:
        payload = {
            "message": parameter1,
            "user_id": parameter2
        }
        response = requests.post(f"{API_SERVER_URL}/send-notification", json=payload)
        response.raise_for_status()
        data = response.json()
        
        # CUSTOMIZE THIS: Return success message
        return f"Notification sent successfully! Message ID: {data.get('message_id')}"
        
    except Exception as e:
        # CUSTOMIZE THIS: Return error message
        return f"Failed to send notification. Error: {str(e)}"


# ADD MORE FUNCTIONS: Copy the pattern above to add more functions
# def your_third_function() -> str:
#     """Your third function description."""
#     # Your implementation here
#     pass

# =====================================
# TOOL REGISTRATION SECTION
# =====================================
# REPLACE THESE: Create tool instances for each of your functions
# The variable name should match your function name + "Tool"
your_first_functionTool = FunctionTool(your_first_function)
your_second_functionTool = FunctionTool(your_second_function)

# ADD MORE TOOLS: Create tool instances for additional functions
# your_third_functionTool = FunctionTool(your_third_function)

# REGISTER TOOLS: Add all your tools to this dictionary
# Key = tool name, Value = tool instance
available_tools = {
    your_first_functionTool.name: your_first_functionTool,
    your_second_functionTool.name: your_second_functionTool,
    # ADD MORE: your_third_functionTool.name: your_third_functionTool,
}

# =====================================
# MCP SERVER SETUP SECTION
# =====================================
# CUSTOMIZE THIS: Change the server name to describe your server
app = Server("Your-Custom-MCP-Server")  # Replace with your server name
sse = SseServerTransport("/messages/")

@app.list_tools()
async def list_tools() -> list[mcp_types.Tool]:
    """
    MCP handler to list available tools.
    DO NOT MODIFY: This function tells the AI what tools are available.
    """
    # Convert each tool to MCP format
    mcp_tools = []
    for tool_name, tool_instance in available_tools.items():
        schema = adk_to_mcp_tool_type(tool_instance)
        mcp_tools.append(schema)
        print(f"MCP Server: Advertising tool: {schema.name}")
    
    print(f"MCP Server: Received list_tools request. Total tools: {len(mcp_tools)}")
    return mcp_tools

@app.call_tool()
async def call_tool(
    name: str, arguments: dict
) -> list[mcp_types.TextContent | mcp_types.ImageContent | mcp_types.EmbeddedResource]:
    """
    MCP handler to execute a tool call.
    DO NOT MODIFY: This function executes the tools when called by the AI.
    """
    print(f"MCP Server: Received call_tool request for '{name}' with args: {arguments}")

    # Look up the tool by name
    tool_to_call = available_tools.get(name)
    if tool_to_call:
        try:
            # Execute the tool
            adk_response = await tool_to_call.run_async(
                args=arguments,
                tool_context=None,
            )
            print(f"MCP Server: Tool '{name}' executed successfully.")
            
            # Return the response as MCP text content
            response_text = json.dumps(adk_response, indent=2)
            return [mcp_types.TextContent(type="text", text=response_text)]

        except Exception as e:
            print(f"MCP Server: Error executing tool '{name}': {e}")
            error_text = json.dumps({"error": f"Failed to execute tool '{name}': {str(e)}"})
            return [mcp_types.TextContent(type="text", text=error_text)]
    else:
        # Handle unknown tools
        print(f"MCP Server: Tool '{name}' not found.")
        error_text = json.dumps({"error": f"Tool '{name}' not implemented."})
        return [mcp_types.TextContent(type="text", text=error_text)]

# =====================================
# SERVER TRANSPORT SECTION
# =====================================
# DO NOT MODIFY: This section handles the communication protocol

async def handle_sse(request):
    """Handles Server-Sent Events for MCP communication."""
    async with sse.connect_sse(
        request.scope, request.receive, request._send
    ) as streams:
        await app.run(
            streams[0], streams[1], app.create_initialization_options()
        )

# Create the Starlette ASGI application
starlette_app = Starlette(
    debug=True,
    routes=[
        Route("/sse", endpoint=handle_sse),
        Mount("/messages/", app=sse.handle_post_message),
    ],
)

# =====================================
# SERVER STARTUP SECTION
# =====================================
# CUSTOMIZE THIS: You can modify the startup messages but keep the core logic

if __name__ == "__main__":
    print("🚀 Launching Your Custom MCP Server...")
    print(f"📡 Server will run on {APP_HOST}:{APP_PORT}")
    print(f"🔧 Available tools: {list(available_tools.keys())}")
    
    try:
        # Start the server
        asyncio.run(uvicorn.run(starlette_app, host=APP_HOST, port=APP_PORT))
    except KeyboardInterrupt:
        print("\n⏹️  MCP Server stopped by user.")
    except Exception as e:
        print(f"❌ MCP Server encountered an error: {e}")
    finally:
        print("🔚 MCP Server process exiting.")

# =====================================
# TEMPLATE USAGE EXAMPLES
# =====================================

"""
EXAMPLE 1: Weather Service MCP Server
--------------------------------------
Replace the functions above with:

def get_weather(city: str) -> str:
    '''Gets current weather for a specified city.'''
    try:
        api_key = os.environ.get('WEATHER_API_KEY')
        response = requests.get(f"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}")
        response.raise_for_status()
        data = response.json()
        temp = data['main']['temp'] - 273.15  # Convert from Kelvin to Celsius
        description = data['weather'][0]['description']
        return f"Weather in {city}: {temp:.1f}°C, {description}"
    except Exception as e:
        return f"Failed to get weather for {city}: {str(e)}"

def get_forecast(city: str, days: int) -> str:
    '''Gets weather forecast for specified city and number of days.'''
    try:
        api_key = os.environ.get('WEATHER_API_KEY')
        response = requests.get(f"https://api.openweathermap.org/data/2.5/forecast?q={city}&cnt={days*8}&appid={api_key}")
        response.raise_for_status()
        data = response.json()
        forecast_summary = f"5-day forecast for {city}:\\n"
        for item in data['list'][::8]:  # Every 8th item (daily)
            date = item['dt_txt'].split()[0]
            temp = item['main']['temp'] - 273.15
            desc = item['weather'][0]['description']
            forecast_summary += f"{date}: {temp:.1f}°C, {desc}\\n"
        return forecast_summary
    except Exception as e:
        return f"Failed to get forecast for {city}: {str(e)}"

# Then register tools:
get_weatherTool = FunctionTool(get_weather)
get_forecastTool = FunctionTool(get_forecast)

available_tools = {
    get_weatherTool.name: get_weatherTool,
    get_forecastTool.name: get_forecastTool,
}

# Change server name:
app = Server("Weather-MCP-Server")

EXAMPLE 2: File Management MCP Server
------------------------------------
def list_files(directory: str) -> str:
    '''Lists all files in the specified directory.'''
    try:
        files = os.listdir(directory)
        return f"Files in {directory}: {', '.join(files)}"
    except Exception as e:
        return f"Error listing files: {str(e)}"

def read_file(filepath: str) -> str:
    '''Reads and returns the content of a text file.'''
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        return f"Content of {filepath}:\\n{content}"
    except Exception as e:
        return f"Error reading file: {str(e)}"

def write_file(filepath: str, content: str) -> str:
    '''Writes content to a specified file.'''
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        return f"Successfully wrote to {filepath}"
    except Exception as e:
        return f"Error writing file: {str(e)}"

EXAMPLE 3: Database MCP Server
-----------------------------
import sqlite3

def query_database(sql: str) -> str:
    '''Executes a SQL query and returns the results.'''
    try:
        conn = sqlite3.connect('database.db')
        cursor = conn.cursor()
        cursor.execute(sql)
        results = cursor.fetchall()
        conn.close()
        return f"Query results: {results}"
    except Exception as e:
        return f"Database error: {str(e)}"

def insert_record(table: str, data: str) -> str:
    '''Inserts a new record into the specified table.'''
    try:
        conn = sqlite3.connect('database.db')
        cursor = conn.cursor()
        cursor.execute(f"INSERT INTO {table} VALUES ({data})")
        conn.commit()
        conn.close()
        return f"Record inserted into {table}"
    except Exception as e:
        return f"Insert error: {str(e)}"

SETUP INSTRUCTIONS:
==================
1. Install dependencies:
   pip install uvicorn python-dotenv requests mcp starlette

2. Create .env file with your configuration:
   APP_HOST=0.0.0.0
   APP_PORT=8080
   API_SERVER_URL=https://your-api.com
   # Add any API keys or secrets here

3. Replace the example functions with your own
4. Update the tool registration section
5. Change the server name
6. Run: python main.py

ENVIRONMENT VARIABLES TO SET:
============================
- APP_HOST: Server host address (default: 0.0.0.0)
- APP_PORT: Server port (default: 8080)
- API_SERVER_URL: External API URL if calling external services
- Add any API keys, database URLs, or other configuration here

CUSTOMIZATION CHECKLIST:
========================
□ Replace function definitions with your own
□ Update function docstrings
□ Register your tools in available_tools dictionary
□ Change server name in Server() constructor
□ Set up environment variables
□ Test your functions work correctly
□ Update startup messages if desired
"""





